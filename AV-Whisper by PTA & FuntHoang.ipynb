{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Xem hướng dẫn tại [đây](https://docs.google.com/document/d/1d3Fp33kRVa50WXEYbYSRs05z2uSFCCyI_pbpnYB0PgU/edit?usp=sharing)**"
      ],
      "metadata": {
        "id": "WVjG6x_wmEPd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coGoZNiCDoEJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown **Kiểm tra GPU** (1 trong 3 GPU này: V100, P100 hoặc T4 thì đã được liên kết GPU từ Colab)\n",
        "!nvidia-smi -L\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Liên kết Google Drive** (bỏ qua nếu up file trực tiếp vào Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kfPCEW38EVga",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxbz10KgDoEK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown **Cài đặt Whisper**\n",
        "%pip install -q deepl srt demucs faster-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-C6kQYHDoEK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown **Load Whisper**\n",
        "#@markdown <br>\n",
        "#@markdown Model càng lớn thì sub càng chuẩn nhưng thời gian lâu hơn\n",
        "#@markdown <br>\n",
        "#@markdown Riêng model mặc định *large-v2* (khuyên dùng) thời gian nhanh hơn *large-v1*\n",
        "model_size = \"large-v2\"  # @param [\"tiny\",\"base\",\"small\",\"medium\", \"large-v1\", \"large-v2\"]\n",
        "\n",
        "import torch, torchaudio, os, srt, datetime, json, deepl, urllib.request, faster_whisper\n",
        "from tqdm import tqdm\n",
        "from google.colab import files as g_files, drive as g_drive\n",
        "from demucs.pretrained import get_model as demucs_get_model\n",
        "from demucs.separate import load_track as demucs_load_track\n",
        "from demucs.apply import apply_model as demucs_apply_model\n",
        "\n",
        "DEMUCS_MODEL = demucs_get_model(\"htdemucs\").cuda()\n",
        "WHISPER_MODEL = faster_whisper.WhisperModel(model_size, device=\"cuda\")\n",
        "\n",
        "PUNCT_MATCH = [\"。\", \"、\", \",\", \".\", \"〜\", \"！\", \"!\", \"？\", \"?\", \"-\"]\n",
        "REMOVE_QUOTES = dict.fromkeys(map(ord, '\"„“‟”＂「」'), None)\n",
        "GARBAGE_LIST = [\n",
        "\t\"a\",\n",
        "\t\"aa\",\n",
        "\t\"ah\",\n",
        "\t\"ahh\",\n",
        "\t\"h\",\n",
        "\t\"ha\",\n",
        "\t\"haa\",\n",
        "\t\"hah\",\n",
        "\t\"haha\",\n",
        "\t\"hahaha\",\n",
        "\t\"hm\",\n",
        "\t\"hmm\",\n",
        "\t\"huh\",\n",
        "\t\"m\",\n",
        "\t\"mh\",\n",
        "\t\"mm\",\n",
        "\t\"mmh\",\n",
        "\t\"mmm\",\n",
        "\t\"o\",\n",
        "\t\"oh\",\n",
        "]\n",
        "NEED_CONTEXT_LINES = [\n",
        "\t\"feelsgod\",\n",
        "\t\"godbye\",\n",
        "\t\"godnight\",\n",
        "\t\"thankyou\",\n",
        "]\n",
        "\n",
        "clean_text = lambda text: (text\n",
        "\t.replace(\".\", \"\")\n",
        "\t.replace(\",\", \"\")\n",
        "\t.replace(\":\", \"\")\n",
        "\t.replace(\";\", \"\")\n",
        "\t.replace(\"!\", \"\")\n",
        "\t.replace(\"?\", \"\")\n",
        "\t.replace(\"-\", \" \")\n",
        "\t.replace(\"  \", \" \")\n",
        "\t.replace(\"  \", \" \")\n",
        "\t.replace(\"  \", \" \")\n",
        "\t.lower()\n",
        "\t.replace(\"that feels\", \"feels\")\n",
        "\t.replace(\"it feels\", \"feels\")\n",
        "\t.replace(\"feels good\", \"feelsgood\")\n",
        "\t.replace(\"good bye\", \"goodbye\")\n",
        "\t.replace(\"good night\", \"goodnight\")\n",
        "\t.replace(\"thank you\", \"thankyou\")\n",
        "\t.replace(\"aaaaaa\", \"a\")\n",
        "\t.replace(\"aaaa\", \"a\")\n",
        "\t.replace(\"aa\", \"a\")\n",
        "\t.replace(\"aa\", \"a\")\n",
        "\t.replace(\"mmmmmm\", \"m\")\n",
        "\t.replace(\"mmmm\", \"m\")\n",
        "\t.replace(\"mm\", \"m\")\n",
        "\t.replace(\"mm\", \"m\")\n",
        "\t.replace(\"hhhhhh\", \"h\")\n",
        "\t.replace(\"hhhh\", \"h\")\n",
        "\t.replace(\"hh\", \"h\")\n",
        "\t.replace(\"hh\", \"h\")\n",
        "\t.replace(\"oooooo\", \"o\")\n",
        "\t.replace(\"oooo\", \"o\")\n",
        "\t.replace(\"oo\", \"o\")\n",
        "\t.replace(\"oo\", \"o\")\n",
        ")\n",
        "\n",
        "TO_LANGUAGE_CODE = { # from https://github.com/openai/whisper/blob/main/whisper/tokenizer.py\n",
        "\t\"afrikaans\": \"af\",\n",
        "\t\"albanian\": \"sq\",\n",
        "\t\"amharic\": \"am\",\n",
        "\t\"arabic\": \"ar\",\n",
        "\t\"armenian\": \"hy\",\n",
        "\t\"assamese\": \"as\",\n",
        "\t\"azerbaijani\": \"az\",\n",
        "\t\"bashkir\": \"ba\",\n",
        "\t\"basque\": \"eu\",\n",
        "\t\"belarusian\": \"be\",\n",
        "\t\"bengali\": \"bn\",\n",
        "\t\"bosnian\": \"bs\",\n",
        "\t\"breton\": \"br\",\n",
        "\t\"bulgarian\": \"bg\",\n",
        "\t\"burmese\": \"my\",\n",
        "\t\"castilian\": \"es\",\n",
        "\t\"catalan\": \"ca\",\n",
        "\t\"chinese\": \"zh\",\n",
        "\t\"croatian\": \"hr\",\n",
        "\t\"czech\": \"cs\",\n",
        "\t\"danish\": \"da\",\n",
        "\t\"dutch\": \"nl\",\n",
        "\t\"english\": \"en\",\n",
        "\t\"estonian\": \"et\",\n",
        "\t\"faroese\": \"fo\",\n",
        "\t\"finnish\": \"fi\",\n",
        "\t\"flemish\": \"nl\",\n",
        "\t\"french\": \"fr\",\n",
        "\t\"galician\": \"gl\",\n",
        "\t\"georgian\": \"ka\",\n",
        "\t\"german\": \"de\",\n",
        "\t\"greek\": \"el\",\n",
        "\t\"gujarati\": \"gu\",\n",
        "\t\"haitian creole\": \"ht\",\n",
        "\t\"haitian\": \"ht\",\n",
        "\t\"hausa\": \"ha\",\n",
        "\t\"hawaiian\": \"haw\",\n",
        "\t\"hebrew\": \"he\",\n",
        "\t\"hindi\": \"hi\",\n",
        "\t\"hungarian\": \"hu\",\n",
        "\t\"icelandic\": \"is\",\n",
        "\t\"indonesian\": \"id\",\n",
        "\t\"italian\": \"it\",\n",
        "\t\"japanese\": \"ja\",\n",
        "\t\"javanese\": \"jw\",\n",
        "\t\"kannada\": \"kn\",\n",
        "\t\"kazakh\": \"kk\",\n",
        "\t\"khmer\": \"km\",\n",
        "\t\"korean\": \"ko\",\n",
        "\t\"lao\": \"lo\",\n",
        "\t\"latin\": \"la\",\n",
        "\t\"latvian\": \"lv\",\n",
        "\t\"letzeburgesch\": \"lb\",\n",
        "\t\"lingala\": \"ln\",\n",
        "\t\"lithuanian\": \"lt\",\n",
        "\t\"luxembourgish\": \"lb\",\n",
        "\t\"macedonian\": \"mk\",\n",
        "\t\"malagasy\": \"mg\",\n",
        "\t\"malay\": \"ms\",\n",
        "\t\"malayalam\": \"ml\",\n",
        "\t\"maltese\": \"mt\",\n",
        "\t\"maori\": \"mi\",\n",
        "\t\"marathi\": \"mr\",\n",
        "\t\"moldavian\": \"ro\",\n",
        "\t\"moldovan\": \"ro\",\n",
        "\t\"mongolian\": \"mn\",\n",
        "\t\"myanmar\": \"my\",\n",
        "\t\"nepali\": \"ne\",\n",
        "\t\"norwegian\": \"no\",\n",
        "\t\"nynorsk\": \"nn\",\n",
        "\t\"occitan\": \"oc\",\n",
        "\t\"panjabi\": \"pa\",\n",
        "\t\"pashto\": \"ps\",\n",
        "\t\"persian\": \"fa\",\n",
        "\t\"polish\": \"pl\",\n",
        "\t\"portuguese\": \"pt\",\n",
        "\t\"punjabi\": \"pa\",\n",
        "\t\"pushto\": \"ps\",\n",
        "\t\"romanian\": \"ro\",\n",
        "\t\"russian\": \"ru\",\n",
        "\t\"sanskrit\": \"sa\",\n",
        "\t\"serbian\": \"sr\",\n",
        "\t\"shona\": \"sn\",\n",
        "\t\"sindhi\": \"sd\",\n",
        "\t\"sinhala\": \"si\",\n",
        "\t\"sinhalese\": \"si\",\n",
        "\t\"slovak\": \"sk\",\n",
        "\t\"slovenian\": \"sl\",\n",
        "\t\"somali\": \"so\",\n",
        "\t\"spanish\": \"es\",\n",
        "\t\"sundanese\": \"su\",\n",
        "\t\"swahili\": \"sw\",\n",
        "\t\"swedish\": \"sv\",\n",
        "\t\"tagalog\": \"tl\",\n",
        "\t\"tajik\": \"tg\",\n",
        "\t\"tamil\": \"ta\",\n",
        "\t\"tatar\": \"tt\",\n",
        "\t\"telugu\": \"te\",\n",
        "\t\"thai\": \"th\",\n",
        "\t\"tibetan\": \"bo\",\n",
        "\t\"turkish\": \"tr\",\n",
        "\t\"turkmen\": \"tk\",\n",
        "\t\"ukrainian\": \"uk\",\n",
        "\t\"urdu\": \"ur\",\n",
        "\t\"uzbek\": \"uz\",\n",
        "\t\"valencian\": \"ca\",\n",
        "\t\"vietnamese\": \"vi\",\n",
        "\t\"welsh\": \"cy\",\n",
        "\t\"yiddish\": \"yi\",\n",
        "\t\"yoruba\": \"yo\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnhSGAnoDoEM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown **Chạy Whisper**<br>\n",
        "#@markdown *Lưu ý: Sao chép đường dẫn của file và dán vào \"audio_path\" trước khi Chạy Whisper*\n",
        "#@markdown <br><br>\n",
        "#@markdown **CÀI ĐẶT TỐI THIỂU:**\n",
        "audio_path = \"\"  # @param {type:\"string\"}\n",
        "language = \"japanese\"  # @param {type:\"string\"}\n",
        "translation_mode = \"transcription + translation\"  # @param [\"transcription only\", \"transcription + translation\", \"transcription + translation with DeepL\"]\n",
        "#@markdown Nếu không dùng DeepL thì bỏ qua 2 mục sau:\n",
        "deepl_authkey = \"\"  # @param {type:\"string\"}\n",
        "deepl_target_lang = \"EN-US\"  # @param {type:\"string\"}\n",
        "#@markdown <br><br/>\n",
        "#@markdown ***CÀI ĐẶT NÂNG CAO*** <br>\n",
        "#@markdown <br>\n",
        "#@markdown Cài đặt SileroVAD:\n",
        "vad_threshold = 0.4  # @param {type:\"number\"}\n",
        "chunk_duration = 3.0  # @param {type:\"number\"}\n",
        "#@markdown Bật \"vocals_extraction\" cho file có thời lượng >1h sẽ tiêu hao nhiều VRAM và dễ gây sập Colab\n",
        "vocals_extraction = False  # @param {type:\"boolean\"}\n",
        "#@markdown 2 mục dưới đây giữ nguyên trừ khi cần tinh chỉnh\n",
        "condition_on_previous_text = True  # @param {type:\"boolean\"}\n",
        "initial_prompt = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# some sanity checks\n",
        "assert vad_threshold >= 0.01\n",
        "assert chunk_duration >= 0.1\n",
        "assert audio_path != \"\"\n",
        "assert language != \"\"\n",
        "language = language.lower()\n",
        "assert language in TO_LANGUAGE_CODE\n",
        "\n",
        "if translation_mode == \"transcription + translation\":\n",
        "\ttask = \"translate\"\n",
        "\trun_deepl = False\n",
        "elif translation_mode == \"transcription + translation with DeepL\":\n",
        "\ttask = \"transcribe\"\n",
        "\trun_deepl = True\n",
        "elif translation_mode == \"transcription only\":\n",
        "\ttask = \"transcribe\"\n",
        "\trun_deepl = False\n",
        "else:\n",
        "\traise ValueError(\"Invalid translation mode\")\n",
        "\n",
        "if initial_prompt.strip() == \"\":\n",
        "\tinitial_prompt = None\n",
        "\n",
        "if \"http://\" in audio_path or \"https://\" in audio_path:\n",
        "\tprint(\"Downloading audio …\")\n",
        "\turllib.request.urlretrieve(audio_path, \"input_file\")\n",
        "\taudio_path = \"input_file\"\n",
        "else:\n",
        "\tif not os.path.exists(audio_path):\n",
        "\t\ttry:\n",
        "\t\t\taudio_path = uploaded_file\n",
        "\t\t\tif not os.path.exists(audio_path):\n",
        "\t\t\t\traise ValueError(\"Không tìm thấy file. audio_path của bạn đã đúng chưa?\")\n",
        "\t\texcept NameError:\n",
        "\t\t\traise ValueError(\"Không tìm thấy file. Bạn đã upload file chưa?\")\n",
        "\n",
        "audiofilebasename = os.path.splitext(audio_path)[0]\n",
        "out_path = audiofilebasename + \".srt\"\n",
        "out_path_pre = audiofilebasename + \"_Untranslated.srt\"\n",
        "\n",
        "if vocals_extraction:\n",
        "\tprint(\"Separating vocals …\")\n",
        "\traw_audio = demucs_load_track(audio_path, DEMUCS_MODEL.audio_channels, DEMUCS_MODEL.samplerate)\n",
        "\t# should not be on GPU because sometimes not enough VRAM\n",
        "\tif raw_audio.dim() == 1:\n",
        "\t\traw_audio = raw_audio[None, None].repeat_interleave(2, -2)\n",
        "\telif raw_audio.shape[-2] == 1:\n",
        "\t\traw_audio = raw_audio.repeat_interleave(2, -2)\n",
        "\telif raw_audio.dim() < 3:\n",
        "\t\traw_audio = raw_audio[None]\n",
        "\tdemucs_extract = demucs_apply_model(DEMUCS_MODEL, raw_audio, device=\"cuda\", split=True, overlap=.25)\n",
        "\ttorch.cuda.empty_cache()\n",
        "\tdemucs_res = demucs_extract[0, DEMUCS_MODEL.sources.index(\"vocals\")].mean(0)[None]\n",
        "\taudio_path = audiofilebasename + \".vocals.wav\"\n",
        "\ttorchaudio.save(audio_path, demucs_res, DEMUCS_MODEL.samplerate)\n",
        "\n",
        "print(\"Đang chạy Whisper … VUI LÒNG ĐỢI MỘT LÁT\")\n",
        "segments, info = WHISPER_MODEL.transcribe(\n",
        "\taudio_path, task=task, language=TO_LANGUAGE_CODE[language],\n",
        "\tcondition_on_previous_text=condition_on_previous_text, initial_prompt=initial_prompt,\n",
        "\tvad_filter=True, vad_parameters=dict(threshold=vad_threshold, max_speech_duration_s=chunk_duration)\n",
        ")\n",
        "\n",
        "subs = []\n",
        "segment_info = []\n",
        "timestamps = 0.0  # for progress bar\n",
        "\n",
        "with tqdm(total=info.duration, unit=\" audio seconds\") as pbar:\n",
        "\tfor i, seg in enumerate(segments, start=1):\n",
        "\t\t# Keep segment info for debugging\n",
        "\t\tsegment_info.append(seg)\n",
        "\t\t# Add to SRT list\n",
        "\t\tsubs.append(srt.Subtitle(\n",
        "\t\t\tindex=i,\n",
        "\t\t\tstart=datetime.timedelta(seconds=seg.start),\n",
        "\t\t\tend=datetime.timedelta(seconds=seg.end),\n",
        "\t\t\tcontent=seg.text.lstrip(),\n",
        "\t\t))\n",
        "\t\tpbar.update(seg.end - timestamps)\n",
        "\t\ttimestamps = seg.end\n",
        "\n",
        "with open(\"segment_info.json\", mode=\"w\", encoding=\"utf8\") as f:\n",
        "\tjson.dump(segment_info, f, indent=4)\n",
        "\n",
        "# DeepL translation\n",
        "translate_error = False\n",
        "if run_deepl:\n",
        "\tprint(\"Translating …\")\n",
        "\twith open(out_path_pre, \"w\", encoding=\"utf8\") as f:\n",
        "\t\tf.write(srt.compose(subs))\n",
        "\tprint(\"(Untranslated subs saved to\", out_path_pre, \")\")\n",
        "\n",
        "\tlines = []\n",
        "\tfor i in range(len(subs)):\n",
        "\t\tif language == \"japanese\":\n",
        "\t\t\tif subs[i].content[-1] not in PUNCT_MATCH:\n",
        "\t\t\t\tsubs[i].content += \"。\"\n",
        "\t\t\tsubs[i].content = \"「\" + subs[i].content + \"」\"\n",
        "\t\telse:\n",
        "\t\t\tif subs[i].content[-1] not in PUNCT_MATCH:\n",
        "\t\t\t\tsubs[i].content += \".\"\n",
        "\t\t\tsubs[i].content = '\"' + subs[i].content + '\"'\n",
        "\tfor i in range(len(subs)):\n",
        "\t\tlines.append(subs[i].content)\n",
        "\n",
        "\tgrouped_lines = []\n",
        "\tenglish_lines = []\n",
        "\tfor i, l in enumerate(lines):\n",
        "\t\tif i % 30 == 0:\n",
        "\t\t\t# Split lines into smaller groups, to prevent error 413\n",
        "\t\t\tgrouped_lines.append([])\n",
        "\t\t\tif i != 0:\n",
        "\t\t\t\t# Include previous 3 lines, to preserve context between splits\n",
        "\t\t\t\tgrouped_lines[-1].extend(grouped_lines[-2][-3:])\n",
        "\t\tgrouped_lines[-1].append(l.strip())\n",
        "\t\t\n",
        "\ttry:\n",
        "\t\ttranslator = deepl.Translator(deepl_authkey)\n",
        "\t\tfor i, n in enumerate(tqdm(grouped_lines)):\n",
        "\t\t\tx = [\"\\n\".join(n).strip()]\n",
        "\t\t\tif language == \"japanese\":\n",
        "\t\t\t\tresult = translator.translate_text(x, source_lang=\"JA\", target_lang=deepl_target_lang)\n",
        "\t\t\telse:\n",
        "\t\t\t\tresult = translator.translate_text(x, target_lang=deepl_target_lang)\n",
        "\t\t\tenglish_tl = result[0].text.strip().splitlines()\n",
        "\t\t\tassert len(english_tl) == len(n), f\"Invalid translation line count ({len(english_tl)} vs {len(n)})\"\n",
        "\t\t\tif i != 0:\n",
        "\t\t\t\tenglish_tl = english_tl[3:]\n",
        "\t\t\tfor e in english_tl:\n",
        "\t\t\t\tenglish_lines.append(\n",
        "\t\t\t\t\te.strip().translate(REMOVE_QUOTES).replace(\"’\", \"'\")\n",
        "\t\t\t\t)\n",
        "\t\tfor i, e in enumerate(english_lines):\n",
        "\t\t\tsubs[i].content = e\n",
        "\texcept Exception as e:\n",
        "\t\tprint(\"DeepL translation error:\", e)\n",
        "\t\tprint(\"(downloading untranslated version instead)\")\n",
        "\t\ttranslate_error = True\n",
        "\n",
        "# Write SRT file\n",
        "if translate_error:\n",
        "\tg_files.download(out_path_pre)\n",
        "else:\n",
        "\t# Removal of garbage lines\n",
        "\tclean_subs = []\n",
        "\tlast_line_garbage = False\n",
        "\tfor i in range(len(subs)):\n",
        "\t\tc = clean_text(subs[i].content)\n",
        "\t\tis_garbage = True\n",
        "\t\tfor w in c.split(\" \"):\n",
        "\t\t\tw_tmp = w.strip()\n",
        "\t\t\tif w_tmp == \"\":\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tif w_tmp in GARBAGE_LIST:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\telif w_tmp in NEED_CONTEXT_LINES and last_line_garbage:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\telse:\n",
        "\t\t\t\tis_garbage = False\n",
        "\t\t\t\tbreak\n",
        "\t\tif not is_garbage:\n",
        "\t\t\tclean_subs.append(subs[i])\n",
        "\t\tlast_line_garbage = is_garbage\n",
        "\twith open(out_path, mode=\"w\", encoding=\"utf8\") as f:\n",
        "\t\tf.write(srt.compose(clean_subs))\n",
        "\tprint(\"\\nHoàn tất! File SRT đã được lưu ở\", out_path)\n",
        "\tprint(\"Đang tải xuống file SRT về máy tính:\")\n",
        "\tg_files.download(out_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
